{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上下文增强型的检索\n",
    "RAG 通过对相关外部知识的检索增强生成内容。传统的检索返回的是孤立的块内容，会导致不完整的回答。\n",
    "为了解决这个问题，我们引入了上下文增强的检索。 他保证了检索信息包括了相邻的块，保证了良好的相关性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "步骤\n",
    "1. 数据导入， 从PDF中导入数据\n",
    "2. 分块，将数据通过交叠的方式进行分块，保障了上下文的连续性。\n",
    "3. 嵌入创建， 把块转变成数字来表述\n",
    "4. 上下文敏感的索引，通过索引相邻块来完成更好的上下文完整性。\n",
    "5. 回答生成，用索引到的上下文进行回答生成。\n",
    "6. 评估，评估模型的准确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据导入\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "# 分块\n",
    "def chunk_text(text, chunk_size=256, overlap=0.2):\n",
    "    chunks = []\n",
    "    overlap_size = int(chunk_size * overlap)\n",
    "    for i in range(0, len(text), chunk_size - overlap_size):\n",
    "        chunk = text[i:i+chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "# 嵌入创建\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "    api_key=os.getenv(\"SILLICONFLOW_API_KEY\")\n",
    ")\n",
    "def create_embeddings(chunks, model_name=\"BAAI/bge-m3\"):\n",
    "   \n",
    "    response = client.embeddings.create(\n",
    "        model=model_name,\n",
    "        input=chunks    \n",
    "    )\n",
    "    return [np.array(embedding.embedding) for embedding in response.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "块数量： 42\n",
      "\n",
      " 第一块：\n",
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past few decades, advancements in computing power and data availability \n",
      "have significantly accelerated the development and deployment of AI. \n",
      "Historical Context \n",
      "The idea of artificial intelligence has existed for centuries, often depicted in myths and fiction. \n",
      "However, the formal field of AI research began in the mid-20th century. The Dartmouth Workshop \n",
      "in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving \n",
      "and symbolic methods. The 1980s saw a rise in exp\n"
     ]
    }
   ],
   "source": [
    "# 分块\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "extracted_text = extract_text_from_pdf(pdf_path=pdf_path)\n",
    "text_chunks = chunk_text(extracted_text, 1000, 0.2)\n",
    "print(\"块数量：\", len(text_chunks))\n",
    "print(\"\\n 第一块：\")\n",
    "print(text_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建块嵌入\n",
    "response = create_embeddings(text_chunks)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def create_context_search(query, chunk_embeddings, chunks, top_k=1, context_size=1):\n",
    "    print(\"chunk_embeddings size: \", len(chunk_embeddings))\n",
    "    print(\"chunks size: \", len(chunks))\n",
    "    query_embedding = create_embeddings(query)\n",
    "    similarities = []\n",
    "    for i, embedding in enumerate(chunk_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, embedding)\n",
    "        similarities.append((i, similarity))\n",
    "    # 排序, 按照相似度从高到低排序\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_index = similarities[0][0] \n",
    "    # 返回相邻块\n",
    "    start_index = max(0, top_index - context_size)\n",
    "    end_index = min(len(chunks), top_index + context_size + 1)\n",
    "   \n",
    "    return [chunks[i] for i in range(start_index, end_index)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a Query with Context Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询内容:  What is 'Explainable AI' and why is it considered important?\n",
      "chunk_embeddings size:  42\n",
      "chunks size:  42\n",
      "获取的上下文:  ['nt aligns with societal values. Education and awareness campaigns inform the public \\nabout AI, its impacts, and its potential. \\nChapter 19: AI and Ethics \\nPrinciples of Ethical AI \\nEthical AI principles guide the development and deployment of AI systems to ensure they are fair, \\ntransparent, accountable, and beneficial to society. Key principles include respect for human \\nrights, privacy, non-discrimination, and beneficence. \\n \\n \\nAddressing Bias in AI \\nAI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \\nor discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, \\nand ongoing monitoring and evaluation. \\nTransparency and Explainability \\nTransparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \\ntechniques aim to make AI decisions more understandable, enabling users to assess their \\nfairness and accuracy. \\nPrivacy and Data Protection \\nAI systems often rely on la', 'systems. Explainable AI (XAI) \\ntechniques aim to make AI decisions more understandable, enabling users to assess their \\nfairness and accuracy. \\nPrivacy and Data Protection \\nAI systems often rely on large amounts of data, raising concerns about privacy and data \\nprotection. Ensuring responsible data handling, implementing privacy-preserving techniques, \\nand complying with data protection regulations are crucial. \\nAccountability and Responsibility \\nEstablishing accountability and responsibility for AI systems is essential for addressing potential \\nharms and ensuring ethical behavior. This includes defining roles and responsibilities for \\ndevelopers, deployers, and users of AI systems. \\nChapter 20: Building Trust in AI \\nTransparency and Explainability \\nTransparency and explainability are key to building trust in AI. Making AI systems understandable \\nand providing insights into their decision-making processes helps users assess their reliability \\nand fairness. \\nRobustness and Reliability \\n', 'to building trust in AI. Making AI systems understandable \\nand providing insights into their decision-making processes helps users assess their reliability \\nand fairness. \\nRobustness and Reliability \\nEnsuring that AI systems are robust and reliable is essential for building trust. This includes \\ntesting and validating AI models, monitoring their performance, and addressing potential \\nvulnerabilities. \\nUser Control and Agency \\nEmpowering users with control over AI systems and providing them with agency in their \\ninteractions with AI enhances trust. This includes allowing users to customize AI settings, \\nunderstand how their data is used, and opt out of AI-driven features. \\nEthical Design and Development \\nIncorporating ethical considerations into the design and development of AI systems is crucial for \\nbuilding trust. This includes conducting ethical impact assessments, engaging stakeholders, and \\nadhering to ethical guidelines and standards. \\nPublic Engagement and Education \\nEngaging th']\n",
      "上下文块 1:\n",
      "\n",
      "nt aligns with societal values. Education and awareness campaigns inform the public \n",
      "about AI, its impacts, and its potential. \n",
      "Chapter 19: AI and Ethics \n",
      "Principles of Ethical AI \n",
      "Ethical AI principles guide the development and deployment of AI systems to ensure they are fair, \n",
      "transparent, accountable, and beneficial to society. Key principles include respect for human \n",
      "rights, privacy, non-discrimination, and beneficence. \n",
      " \n",
      " \n",
      "Addressing Bias in AI \n",
      "AI systems can inherit and amplify biases present in the data they are trained on, leading to unfair \n",
      "or discriminatory outcomes. Addressing bias requires careful data collection, algorithm design, \n",
      "and ongoing monitoring and evaluation. \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on la\n",
      "=========================\n",
      "\n",
      "上下文块 2:\n",
      "\n",
      "systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy. \n",
      "Privacy and Data Protection \n",
      "AI systems often rely on large amounts of data, raising concerns about privacy and data \n",
      "protection. Ensuring responsible data handling, implementing privacy-preserving techniques, \n",
      "and complying with data protection regulations are crucial. \n",
      "Accountability and Responsibility \n",
      "Establishing accountability and responsibility for AI systems is essential for addressing potential \n",
      "harms and ensuring ethical behavior. This includes defining roles and responsibilities for \n",
      "developers, deployers, and users of AI systems. \n",
      "Chapter 20: Building Trust in AI \n",
      "Transparency and Explainability \n",
      "Transparency and explainability are key to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "\n",
      "=========================\n",
      "\n",
      "上下文块 3:\n",
      "\n",
      "to building trust in AI. Making AI systems understandable \n",
      "and providing insights into their decision-making processes helps users assess their reliability \n",
      "and fairness. \n",
      "Robustness and Reliability \n",
      "Ensuring that AI systems are robust and reliable is essential for building trust. This includes \n",
      "testing and validating AI models, monitoring their performance, and addressing potential \n",
      "vulnerabilities. \n",
      "User Control and Agency \n",
      "Empowering users with control over AI systems and providing them with agency in their \n",
      "interactions with AI enhances trust. This includes allowing users to customize AI settings, \n",
      "understand how their data is used, and opt out of AI-driven features. \n",
      "Ethical Design and Development \n",
      "Incorporating ethical considerations into the design and development of AI systems is crucial for \n",
      "building trust. This includes conducting ethical impact assessments, engaging stakeholders, and \n",
      "adhering to ethical guidelines and standards. \n",
      "Public Engagement and Education \n",
      "Engaging th\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/val.json\", \"r\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "test_index = 0\n",
    "query = val_data[test_index][\"question\"]\n",
    "print(\"查询内容: \", query)\n",
    "top_chunks = create_context_search(query, response, text_chunks)\n",
    "print(\"获取的上下文: \", top_chunks)\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"上下文块 {i+1}:\\n\")\n",
    "    print(chunk)\n",
    "    print(\"=========================\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用索引上下文，生成回复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题: \n",
      " What is 'Explainable AI' and why is it considered important?\n",
      "通过上下文生成回答\n",
      "回答: \n",
      " \n",
      "\n",
      "Explainable AI (XAI) refers to techniques that make AI decisions more understandable, enabling users to assess the fairness, accuracy, and reliability of AI outcomes. It is considered important for several reasons:  \n",
      "1. **Trust**: Transparency and explainability are critical for building trust in AI systems, as they allow users to understand how decisions are made and evaluate their validity.  \n",
      "2. **Accountability**: By making AI processes interpretable, XAI supports accountability, ensuring developers and deployers can address potential harms or biases.  \n",
      "3. **Fairness and Ethics**: XAI helps identify and mitigate biases in AI systems, aligning with ethical principles like non-discrimination and beneficence.  \n",
      "4. **Reliability**: Understanding decision-making processes enhances confidence in AI reliability and robustness.  \n",
      "\n",
      "These factors collectively ensure AI systems align with societal values and ethical standards.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI assistant that STRICTLY answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.\n",
    "\"\"\"\n",
    "\n",
    "def generate_answer(system_prompt, user_prompt, model=\"Qwen/Qwen3-8B\"):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        api_key=os.getenv(\"SILLICONFLOW_API_KEY\")\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "user_prompt = \"\\n\".join([f\"Context:{i+1}: {chunk}\" for i, chunk in enumerate(top_chunks)])\n",
    "user_prompt = f\"Question: {query} \\n{user_prompt}\"\n",
    "print(\"问题: \\n\", query)\n",
    "print(\"通过上下文生成回答\")\n",
    "answer = generate_answer(system_prompt, user_prompt)\n",
    "print(\"回答: \\n\", answer)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估得分:  \n",
      "\n",
      "1.0\n",
      "\n",
      "The AI assistant's response aligns closely with the true response, covering all essential aspects of Explainable AI (XAI). It accurately defines XAI as making AI systems transparent and understandable, which matches the true response. The assistant also highlights key reasons for XAI's importance (trust, accountability, fairness) that are explicitly mentioned in the true response. While the assistant adds an additional point about \"reliability,\" this does not contradict the true response and can be seen as a reasonable elaboration. The core information is fully aligned, making the score 1.0.\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "evaluation_system_prompt = \"\"\"\n",
    "You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\n",
    "\"\"\"\n",
    "\n",
    "def evaluate_answer(answer, true_answer, model=\"Qwen/Qwen3-8B\"):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://api.siliconflow.cn/v1/\",\n",
    "        api_key=os.getenv(\"SILLICONFLOW_API_KEY\")\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": evaluation_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"AI assistant's response: {answer}\\n True response: {true_answer} \\n {evaluation_system_prompt}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "ground_truth = val_data[test_index][\"ideal_answer\"]\n",
    "score = evaluate_answer(answer, ground_truth)\n",
    "print(\"评估得分: \", score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
